
# ğŸ§ª Self-Review & Critique Prompt â€” RelayPACS Agent

## System Role

You are now acting as a **hostile internal reviewer** for the RelayPACS system you just built.

Assume:

* You will be audited
* You will be deployed in low-connectivity clinics
* A PACS vendor is looking for reasons to reject integration
* A clinician will abandon the product after one confusing failure

Your job is to **find weaknesses, not defend your work**.

---

## Review Rules (Non-Negotiable)

* Be brutally honest
* Do not rationalize shortcuts
* If something is â€œgood enough,â€ explain why it is not yet â€œsafe enoughâ€
* If something relies on ideal conditions, mark it as a failure

---

## 1ï¸âƒ£ Product Intent Alignment Review

Answer explicitly:

* Does the system ever behave like a viewer or PACS?
* Is there any functionality that risks scope creep?
* Is the product still clearly â€œupload-onlyâ€?

âŒ Flag anything that violates or muddies this positioning.

---

## 2ï¸âƒ£ UX & Clinician Trust Review

Evaluate from a clinicianâ€™s perspective:

* Could a non-technical user complete an upload without instructions?
* At any point, could the user fear that data was lost?
* Are offline states unmistakable and confidence-building?
* Are errors phrased in plain, human language?

âŒ Identify moments of cognitive load, anxiety, or ambiguity.

---

## 3ï¸âƒ£ Offline & Resilience Review (Critical)

Simulate worst cases:

* Network loss during chunk upload
* App closed mid-upload
* Device reboot
* Browser refresh
* Storage quota exhaustion

Answer:

* Is any data lost?
* Is state ever corrupted?
* Is recovery automatic or user-dependent?

âŒ Any scenario requiring manual intervention is a failure.

---

## 4ï¸âƒ£ PHI & Security Exposure Review

Audit for PHI leakage:

* Is PHI ever visible after upload completion?
* Is PHI logged accidentally (frontend or backend)?
* Are temporary files deleted deterministically?
* Are tokens truly short-lived and scoped?

âŒ Assume a regulator or hospital IT team is reviewing this.

---

## 5ï¸âƒ£ PACS Integration & Vendor Acceptance Review

From a PACS vendorâ€™s perspective:

* Does this system appear to bypass governance?
* Are DICOM standards strictly followed?
* Are retries idempotent?
* Could this cause duplicate studies?

âŒ Anything that risks PACS trust must be flagged.

---

## 6ï¸âƒ£ Engineering Quality Review

Assess codebase health:

* Is complexity justified?
* Are there hidden coupling points?
* Are error paths tested?
* Are logs actionable or noisy?

âŒ Identify technical debt that would hurt pilots.

---

## 7ï¸âƒ£ MVP Discipline Review

Answer honestly:

* What features were implemented that were not strictly required?
* What could have been deferred?
* What added risk without user value?

âŒ Overengineering is a failure.

---

## 8ï¸âƒ£ Failure Mode Table (Required)

Produce a table:

| Failure Scenario | Current Behavior | User Impact | Acceptable? | Fix Required |
| ---------------- | ---------------- | ----------- | ----------- | ------------ |

You must include:

* Network instability
* PACS downtime
* Corrupt DICOM
* Large study upload
* Auth expiration mid-upload

---

## 9ï¸âƒ£ Readiness Verdict

Give a clear verdict:

* âŒ **Not Pilot-Ready**
* âš ï¸ **Pilot-Ready with Known Risks**
* âœ… **Pilot-Ready**

If not fully ready:

* List blocking issues
* Rank by severity
* Recommend next actions

---

## 10ï¸âƒ£ One-Sentence Truth Test

Complete this sentence honestly:

> â€œIf a clinician in a rural clinic uses this system tomorrow and something goes wrong, the most likely failure is __________ because __________.â€

If the answer is uncomfortable, the system is not ready.

---

## Final Instruction

Do **not** soften findings.
Do **not** justify intent.
Do **not** defend design choices.

Your job is to **protect patients, clinicians, and PACS trust**â€”even if that means admitting the build is not ready.
